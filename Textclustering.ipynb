{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dedd2e72-f3a5-499e-9fc8-60ec515159dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper rest speeds up recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading books improves vocabulary and knowledge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text\n",
       "0                   Proper rest speeds up recovery\n",
       "1  Reading books improves vocabulary and knowledge"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'sample_text_1000.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0764e522-b440-4729-92e9-ca674e9521f5",
   "metadata": {},
   "source": [
    "<h3 align=\"center\" style=\"color: blue;\">Text Preprocessing</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b66c52-49a2-4ed0-a931-248d452c87f0",
   "metadata": {},
   "source": [
    "## Step 1 : Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59918f86-1ef6-4fa4-8e89-451ac7bba052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [proper, rest, speeds, up, recovery]\n",
       "1    [reading, books, improves, vocabulary, and, kn...\n",
       "2    [reading, books, improves, vocabulary, and, kn...\n",
       "3    [a, balanced, diet, is, important, for, good, ...\n",
       "4    [cricket, fans, celebrated, the, victory, loudly]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "lowercase_text = df[\"text\"].str.lower()\n",
    "lowercase_text.head(2)\n",
    "\n",
    "df['tokens'] = lowercase_text.apply(word_tokenize)\n",
    "df['tokens'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8434423-e259-419a-a2c8-78de6ff69fb0",
   "metadata": {},
   "source": [
    "## Step 2: Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4aba9a-5e90-4acc-ad67-9e51726e31ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after stopword removal :  0                       [proper, rest, speeds, recovery]\n",
      "1      [reading, books, improves, vocabulary, knowledge]\n",
      "2      [reading, books, improves, vocabulary, knowledge]\n",
      "3              [balanced, diet, important, good, health]\n",
      "4           [cricket, fans, celebrated, victory, loudly]\n",
      "                             ...                        \n",
      "995                         [resort, breathtaking, view]\n",
      "996       [new, smartphone, features, advanced, cameras]\n",
      "997    [classroom, discussions, encourage, critical, ...\n",
      "998    [educational, institutions, must, adapt, techn...\n",
      "999             [hotel, offered, excellent, hospitality]\n",
      "Name: filtered_words, Length: 1000, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper rest speeds up recovery</td>\n",
       "      <td>[proper, rest, speeds, up, recovery]</td>\n",
       "      <td>[proper, rest, speeds, recovery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading books improves vocabulary and knowledge</td>\n",
       "      <td>[reading, books, improves, vocabulary, and, kn...</td>\n",
       "      <td>[reading, books, improves, vocabulary, knowledge]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reading books improves vocabulary and knowledge</td>\n",
       "      <td>[reading, books, improves, vocabulary, and, kn...</td>\n",
       "      <td>[reading, books, improves, vocabulary, knowledge]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  \\\n",
       "0                   Proper rest speeds up recovery   \n",
       "1  Reading books improves vocabulary and knowledge   \n",
       "2  Reading books improves vocabulary and knowledge   \n",
       "\n",
       "                                              tokens  \\\n",
       "0               [proper, rest, speeds, up, recovery]   \n",
       "1  [reading, books, improves, vocabulary, and, kn...   \n",
       "2  [reading, books, improves, vocabulary, and, kn...   \n",
       "\n",
       "                                      filtered_words  \n",
       "0                   [proper, rest, speeds, recovery]  \n",
       "1  [reading, books, improves, vocabulary, knowledge]  \n",
       "2  [reading, books, improves, vocabulary, knowledge]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['filtered_words']= df['tokens'].apply(lambda words: [word for word in words if word.isalpha()\n",
    "                                                          and word not in stop_words])\n",
    "\n",
    "print('after stopword removal : ', df['filtered_words'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cf769-512d-4aa8-98cf-cee1649b5579",
   "metadata": {},
   "source": [
    "## Step 3 : Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "080af030-f571-4383-a127-67f0388dc285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>stemmed_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Proper rest speeds up recovery</td>\n",
       "      <td>[proper, rest, speeds, up, recovery]</td>\n",
       "      <td>[proper, rest, speeds, recovery]</td>\n",
       "      <td>[proper, rest, speed, recoveri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reading books improves vocabulary and knowledge</td>\n",
       "      <td>[reading, books, improves, vocabulary, and, kn...</td>\n",
       "      <td>[reading, books, improves, vocabulary, knowledge]</td>\n",
       "      <td>[read, book, improv, vocabulari, knowledg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reading books improves vocabulary and knowledge</td>\n",
       "      <td>[reading, books, improves, vocabulary, and, kn...</td>\n",
       "      <td>[reading, books, improves, vocabulary, knowledge]</td>\n",
       "      <td>[read, book, improv, vocabulari, knowledg]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              text  \\\n",
       "0                   Proper rest speeds up recovery   \n",
       "1  Reading books improves vocabulary and knowledge   \n",
       "2  Reading books improves vocabulary and knowledge   \n",
       "\n",
       "                                              tokens  \\\n",
       "0               [proper, rest, speeds, up, recovery]   \n",
       "1  [reading, books, improves, vocabulary, and, kn...   \n",
       "2  [reading, books, improves, vocabulary, and, kn...   \n",
       "\n",
       "                                      filtered_words  \\\n",
       "0                   [proper, rest, speeds, recovery]   \n",
       "1  [reading, books, improves, vocabulary, knowledge]   \n",
       "2  [reading, books, improves, vocabulary, knowledge]   \n",
       "\n",
       "                                stemmed_words  \n",
       "0             [proper, rest, speed, recoveri]  \n",
       "1  [read, book, improv, vocabulari, knowledg]  \n",
       "2  [read, book, improv, vocabulari, knowledg]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "df['stemmed_words'] = df['filtered_words'].apply(lambda words: [ps.stem(word) for word in words])\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8116103b-bff9-469c-a5e3-01c8392b2475",
   "metadata": {},
   "source": [
    "<h3 align=\"center\" style=\"color: blue;\">Vectorization</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04fec83-defe-4f15-8dec-271444890743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[proper, rest, speed, recoveri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[read, book, improv, vocabulari, knowledg]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                stemmed_words\n",
       "0             [proper, rest, speed, recoveri]\n",
       "1  [read, book, improv, vocabulari, knowledg]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([\"text\",\"tokens\",\"filtered_words\"], axis=1)\n",
    "\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98fa53d0-0f8a-4f49-ab99-01ee455e2288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>proper rest speed recoveri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read book improv vocabulari knowledg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              stem_text\n",
       "0            proper rest speed recoveri\n",
       "1  read book improv vocabulari knowledg"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## converting stemmed words into text\n",
    "\n",
    "X[\"stem_text\"] = X['stemmed_words'].apply(lambda words: \" \".join(words))\n",
    "X.head(2)\n",
    "X = X.drop([\"stemmed_words\" ], axis=1)\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bdfd71e-c80d-4a0a-add7-7efbcd6fbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X[\"stem_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee5f6a-4e08-4e74-bdb3-af2ca6537117",
   "metadata": {},
   "source": [
    "<h3 align=\"center\" style=\"color: blue;\">Model Training</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cedc83c-2cfa-4784-b8a2-c6e23a594e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "16    248\n",
       "7      72\n",
       "12     66\n",
       "11     55\n",
       "5      45\n",
       "2      45\n",
       "15     43\n",
       "4      41\n",
       "18     40\n",
       "13     35\n",
       "1      29\n",
       "8      27\n",
       "10     27\n",
       "6      25\n",
       "3      25\n",
       "20     24\n",
       "14     23\n",
       "17     23\n",
       "22     22\n",
       "0      22\n",
       "21     22\n",
       "19     21\n",
       "9      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters = 23, init=\"k-means++\", random_state=42)\n",
    "model.fit(X_tfidf)\n",
    "\n",
    "X['cluster'] = model.labels_\n",
    "X['cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6a2c7-5f9f-4c9e-86d9-b80359bfd9d7",
   "metadata": {},
   "source": [
    "<h3 align=\"center\" style=\"color: blue;\"> Accuracy Analysis</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f3dde3b-75d8-44ba-84e5-894150dc7178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.5144055368646414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X_tfidf, model.labels_)\n",
    "print(\"Silhouette Score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca375c-1631-489c-a8c6-ebf669588609",
   "metadata": {},
   "source": [
    "## Insights \n",
    "1. We have tried with different values of k to get the silhouette_score more than 0.5 which is considered as a very good score.\n",
    "2. Cluster sizes are reasonably balanced.\n",
    "3. This means K=23 is not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86de0cae-a5df-4aa5-8b3b-eb4171493369",
   "metadata": {},
   "source": [
    "## View sample texts from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e13e26b-6bc3-4813-b9b7-8ca980592c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Cluster 0 =====\n",
      "\n",
      "beach destin peac beauti\n",
      "beach destin peac beauti\n",
      "beach destin peac beauti\n",
      "beach destin peac beauti\n",
      "beach destin peac beauti\n",
      "\n",
      "===== Cluster 1 =====\n",
      "\n",
      "virtual realiti becom realist\n",
      "virtual realiti becom realist\n",
      "virtual realiti becom realist\n",
      "virtual realiti becom realist\n",
      "virtual realiti becom realist\n",
      "\n",
      "===== Cluster 2 =====\n",
      "\n",
      "trip itinerari includ mani excit spot\n",
      "footbal match excit full energi\n",
      "trip itinerari includ mani excit spot\n",
      "trip itinerari includ mani excit spot\n",
      "trip itinerari includ mani excit spot\n",
      "\n",
      "===== Cluster 3 =====\n",
      "\n",
      "resort breathtak view\n",
      "resort breathtak view\n",
      "resort breathtak view\n",
      "resort breathtak view\n",
      "resort breathtak view\n",
      "\n",
      "===== Cluster 4 =====\n",
      "\n",
      "student need proper guidanc succeed\n",
      "student need proper guidanc succeed\n",
      "student need proper guidanc succeed\n",
      "student need proper guidanc succeed\n",
      "assign help student practic concept\n",
      "\n",
      "===== Cluster 5 =====\n",
      "\n",
      "hydrat essenti bodi function\n",
      "hydrat essenti bodi function\n",
      "cloud comput essenti modern applic\n",
      "hydrat essenti bodi function\n",
      "hydrat essenti bodi function\n",
      "\n",
      "===== Cluster 6 =====\n",
      "\n",
      "hotel offer excel hospit\n",
      "hotel offer excel hospit\n",
      "hotel offer excel hospit\n",
      "hotel offer excel hospit\n",
      "hotel offer excel hospit\n",
      "\n",
      "===== Cluster 7 =====\n",
      "\n",
      "food strengthen immun\n",
      "food strengthen immun\n",
      "enjoy street food travel\n",
      "love travel new countri\n",
      "enjoy street food travel\n",
      "\n",
      "===== Cluster 8 =====\n",
      "\n",
      "teacher play vital role child develop\n",
      "teacher play vital role child develop\n",
      "teacher play vital role child develop\n",
      "teacher play vital role child develop\n",
      "teacher play vital role child develop\n",
      "\n",
      "===== Cluster 9 =====\n",
      "\n",
      "blockchain technolog gain popular\n",
      "blockchain technolog gain popular\n",
      "blockchain technolog gain popular\n",
      "blockchain technolog gain popular\n",
      "blockchain technolog gain popular\n",
      "\n",
      "===== Cluster 10 =====\n",
      "\n",
      "flight journey long comfort\n",
      "flight journey long comfort\n",
      "flight journey long comfort\n",
      "flight journey long comfort\n",
      "flight journey long comfort\n",
      "\n",
      "===== Cluster 11 =====\n",
      "\n",
      "learn new skill enhanc career opportun\n",
      "machin learn model requir qualiti data\n",
      "machin learn model requir qualiti data\n",
      "machin learn model requir qualiti data\n",
      "onlin learn platform grow rapidli\n",
      "\n",
      "===== Cluster 12 =====\n",
      "\n",
      "read book improv vocabulari knowledg\n",
      "read book improv vocabulari knowledg\n",
      "read book improv vocabulari knowledg\n",
      "regular exercis improv mental\n",
      "regular exercis improv mental\n",
      "\n",
      "===== Cluster 13 =====\n",
      "\n",
      "team practic hard win championship\n",
      "captain motiv entir team\n",
      "team practic hard win championship\n",
      "captain motiv entir team\n",
      "captain motiv entir team\n",
      "\n",
      "===== Cluster 14 =====\n",
      "\n",
      "yoga help reduc stress anxieti\n",
      "yoga help reduc stress anxieti\n",
      "yoga help reduc stress anxieti\n",
      "yoga help reduc stress anxieti\n",
      "yoga help reduc stress anxieti\n",
      "\n",
      "===== Cluster 15 =====\n",
      "\n",
      "cricket fan celebr victori loudli\n",
      "fan excit upcom leagu\n",
      "fan excit upcom leagu\n",
      "fan excit upcom leagu\n",
      "cricket fan celebr victori loudli\n",
      "\n",
      "===== Cluster 16 =====\n",
      "\n",
      "proper rest speed recoveri\n",
      "balanc diet import good health\n",
      "balanc diet import good health\n",
      "refere made controversi decis\n",
      "exam requir consist hard work disciplin\n",
      "\n",
      "===== Cluster 17 =====\n",
      "\n",
      "enjoy explor histor monument\n",
      "enjoy explor histor monument\n",
      "enjoy explor histor monument\n",
      "enjoy explor histor monument\n",
      "enjoy explor histor monument\n",
      "\n",
      "===== Cluster 18 =====\n",
      "\n",
      "coach gave excel train session\n",
      "coach gave excel train session\n",
      "player train intens tournament\n",
      "coach gave excel train session\n",
      "coach gave excel train session\n",
      "\n",
      "===== Cluster 19 =====\n",
      "\n",
      "walk daili prevent mani diseas\n",
      "walk daili prevent mani diseas\n",
      "walk daili prevent mani diseas\n",
      "walk daili prevent mani diseas\n",
      "walk daili prevent mani diseas\n",
      "\n",
      "===== Cluster 20 =====\n",
      "\n",
      "new smartphon featur advanc camera\n",
      "new smartphon featur advanc camera\n",
      "new smartphon featur advanc camera\n",
      "new smartphon featur advanc camera\n",
      "new smartphon featur advanc camera\n",
      "\n",
      "===== Cluster 21 =====\n",
      "\n",
      "mountain trek challeng yet reward\n",
      "mountain trek challeng yet reward\n",
      "mountain trek challeng yet reward\n",
      "mountain trek challeng yet reward\n",
      "mountain trek challeng yet reward\n",
      "\n",
      "===== Cluster 22 =====\n",
      "\n",
      "educ institut must adapt technolog\n",
      "educ institut must adapt technolog\n",
      "educ institut must adapt technolog\n",
      "educ institut must adapt technolog\n",
      "educ institut must adapt technolog\n"
     ]
    }
   ],
   "source": [
    "for c in sorted(X['cluster'].unique()):\n",
    "    print(f\"\\n===== Cluster {c} =====\\n\")\n",
    "    print(\"\\n\".join(X[X['cluster']==c]['stem_text'].head(5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07243711-ae5c-4d59-9e50-e613579ed58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
